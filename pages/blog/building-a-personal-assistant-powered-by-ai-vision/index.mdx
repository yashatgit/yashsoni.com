---
date: '2021-03-21'
title: 'Building a Personal Assistant powered by AI : Vision'
description: 'my evergrowing learning playground'
keywords: 'Assistant,digital assistant,AI,JARVIS,Vision,dialogflow, openai, smart lamps'
---

import MediaGrid from '../../../components/mediaGrid'

import rpi_schematics from './media/rpi_schematics.jpg'
import rpi_fan from './media/rpi_with_casing_and_fan.jpg'
import assistant_complexity from './media/assistant_complexity.jpg'
import vision_frame_1 from './media/vision_frame_1.jpg'
import vision_frame_2 from './media/vision_frame_2.jpg'
import vision_schematics from './media/vision_schematics.jpg'
import vision_screen from './media/vision_screen.jpg'

import vision_app from './media/vision_app_poster.jpg'
import vision_app_icon from './media/vision_app_icon.jpg'
import vision_app_video from './media/vision_app.mp4'

import vision_commanCenter_off from './media/vision_commanCenter_off.jpg'
import vision_commanCenter_on from './media/vision_commanCenter_on.jpg'
import vision_demo from './media/vision_demo.mp4'
import vision_demo_poster from './media/vision_demo_poster.jpg'

Wikipedia describes a [Personal Assistant](https://en.wikipedia.org/wiki/Personal_assistant) as a person who assists you with your daily business or personal tasks.
A [Digital Personal Assistant](https://en.wikipedia.org/w/index.php?title=Digital_personal_assistant) on the other hand can be described as a [software agent](https://en.wikipedia.org/wiki/Software_agent) that can perform tasks or services for an individual based on commands or questions.

I always thought about what a digital personal assistant would help me with?
On one end of the spectrum, we can even consider a simple TODO app as an assistant that helps you manage and recollect things you want to complete.
On the other end, you have the famous **Iron-Man’s** personal AI-based assistant [**J.A.R.V.I.S.**](https://marvelcinematicuniverse.fandom.com/wiki/J.A.R.V.I.S.) (**Just A Rather Very Intelligent System**).
Whenever I thought of build something on this line, the common obstacle was to figure out where to start and the technical complexities which lies ahead at each step.

<MediaGrid photos={[{src: assistant_complexity}]}/>

Anyhow, I began working on this and to overcome the technical complexities, I treated this project as my learning playground.
Whatever topic I wish to learn, I learn it and apply those learnings back in here.
As a result, this every-growing project has helped me grasp a lot of understanding behind IoT, Networking, Machine Learning, and AI.

The idea of this post is to show what I have been able to build so far, get feedback and, help inspire others to build.
Although, what I have here is maybe **0.1%** of what JARVIS can do in the movies; it is a start nonetheless.

### Establishing an Identity

To ensure the fate of this project doesn’t end with other failed side-projects of mine, what helped is assigning an Identity to this project.
JARVIS was already too mainstream, and it’s [hard to name things](https://martinfowler.com/bliki/TwoHardThings.html) anyways,
so I thought of calling it the next best thing - **Vision**.

Having an established Identity also helped me to not think of Vision as some program that lives in the code terminal, but to give it all forms of expression. Be it having a display to show what goes on behind the scenes, to having a voice, giving it an ability to see stuff and, adding a bit of humor.

### Assembling the Hardware

#### CPU and Peripherals

Vision currently runs on a [Raspberry Pi 3 B+](https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/) (RPI) single-board computer. The powerful CPU coupled with Wireless LAN and Bluetooth 4.1 radio made it an ideal candidate for this project. RPI has a good support to connect external peripherals to extend the capabilities.

<MediaGrid caption="RPI with fan and attached heat sinks" photos={[{src: rpi_schematics, width: 2824,height: 1728}, {src: rpi_fan, width: 1322,height: 1326}]}/>

- For audio capabilities, I connected the RPI to a speaker system and a microphone.
- For the display out, I plugged in an old LDC monitor to the inbuilt HDMI socket.
- To provide visual support, RPI has an [official camera module](https://www.raspberrypi.org/products/camera-module-v2/) that can be attached to the inbuilt camera slot using a ribbon cable. It has an 8-megapixel sensor which is sufficient for still photographs and video recording.

#### Cooling System

To keep the system up and running 24x7, I had to ensure there was optimum cooling support.
Although RPI is programmed to throttle the clock speed to maintain a safe temperature, I couldn’t trust this with the hot and humid weather of India where the temperature reaches 45-48 °C in Summer.
I glued some [Aluminium heat sinks](https://www.amazon.in/LoveRPi-Heatsink-Raspberry-Model-Heatsinks/dp/B018BGRDVS) with thermal tape for some extra heat dissipation.
Then, I mounted this assembly inside a case and attached a [5V heat radiator fan](https://www.amazon.in/gp/product/B01K5S8RH4/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1).
This configuration kept the core temperature of the RPI ~55 °C. On earlier attempts, without this cooling setup, the temperature rose to 80 °C when kept running for more than 24hrs.

#### External Frame

The hardware setup more or less done and I was left with a tangled mess of wires and cables!
The next task was to assemble everything up in a neat way and giving Vision a sturdy enclosure - a body.
Although I wanted to go totally overboard with this idea, I had to curb my intentions given my poor hardware skills.
Looking for some ideas, I stumbled upon a project named [Magic Mirror](https://www.raspberrypi.org/blog/magic-mirror/) which involves the idea of housing the RPI set up in front of a [2-way mirror](https://www.youtube.com/watch?v=fESC9B-GONI&t=61s) and a LCD screen.

I drew up some schematics of the frame and visited a local carpenter to help me build a wooden frame. Once the frame was ready, I Installed a 2-way mirror in the frame and fixed the LCD behind it.
This way if the LCD is off, the frame acts as a normal mirror. On powering on the screen, the 2-way property of the mirror allows what’s behind the screen to show up on the Mirror!

<MediaGrid caption="" photos={[{src: vision_screen, width: 1400,height: 898}, {src: vision_frame_1, width: 1198,height: 1600}, {src: vision_frame_2, width: 1050,height: 1400}]}/>

The final steps were to add some electrical switches on the frame, conceal all the hardware cables, and hanging it on a wall.

### Coding the Software

Once the structure was built, it was time to program it.

#### Interfaces

Vision currently has the following ways to enable interaction with the outside world.

- **Command Center** <br/>
  The LCD screen gave me a big real estate to show up different data points that I frequently consumed throughout the day. I found a great open-source software named Magic Mirror which provides an Electron App with a widget-based interface. There are amazing community built widgets which can be directly used. I authored a few widgets that helped solved some particular use-cases of mine.

- **Mobile App**<br/>
  To make Vision accessible by anyone in our Home local network, there's an App hosted on LAN that allows me to have 2-way communication with it.
  The app helps me relay information in form of chat and voice commands. There are custom widgets that helps play songs on Spotify and interact with all the connected Smart lamps.

- **Natural Language Voice Interface**<br/>
  There's a mic housed inside the command center casing to speak to Vision. The natural language processing is provided by [Dialogflow](https://cloud.google.com/dialogflow).
  It uses machine learning to extract the intent behind the given commands.
  These intents then are mapped to the various commands and actions.

- **Natural Language Instant Messaging Interface**<br/>
  Anything that can be spoken can be typed too. The same parsing system allows me to extract the intent from the chat messages. This comes real handy when the microphone is out of reach.

<MediaGrid caption="Vision App Interface" photos={[{src: vision_app_icon, width: 730,height: 1600}, {src: vision_app_video, poster: vision_app, width: 646,height: 1400}]}/>

<MediaGrid caption="Vision Command Center Interface" photos={[{src: vision_commanCenter_off, width: 1600,height: 2133}, {src: vision_demo, poster: vision_demo_poster, width: 676,height: 1201}]}/>

#### Controls

These are the current set of tasks Vision is able to perform.

- **Weather and forecast**: <br/>
  Shows latest weather updates and weekly forecast. The APIs are powered by [OpenWeather](https://openweathermap.org/api).

- **Newsfeed** <br/>
  Displays the latest headlines - AdFree.
  News is displayed by pooling the RSS feeds of different News publishers

- **Realtime Air Quality Meter** <br/>
  Living in the [most polluted city in the world](https://twitter.com/theworldindex/status/1103197455066247169?s=20) is not easy. To keep the residents informed, our condominium has installed an AQI meter that shows the data on an App.
  This module pools the app servers to fetch the real-time AQI that helps us identify when it is safe to step out of the house and maybe go for a run.

- **Realtime Traffic updates** <br/>
  There has to be a source to the deadly air quality right? One of it is due to pollution from excessive traffic.
  There had been many instances where after stepping from the house I found myself stuck dead in a heavy traffic Jam. This widget pools the Google Maps APIs to help us find the right time to leave our for offices.

- **Daily meal planner** <br/>
  We figured out that one of the easiest ways to stick to a healthy diet is to plan your meals! We prepare a weekly meal plan which helps us plan for the diet earlier and ensures we have the ingredients ready. The data is pulled from an Airtable which we populate weekly.

- **Calendar notifications** <br/>
  This module fetches the latest events from our family calendar and announces them 20 mins prior. To make the notification interesting, I made Vision announce them in its voice.

- **Spotify Player** <br/>
  Makes Vision a [**Spotify connect**](https://support.spotify.com/us/article/spotify-connect/) client.
  This makes Vision visible on our family Spotify Account helping anyone play songs on the attached music system.

- **Mood Setter** <br/>
  At 7 am Vision plays one Spotify playlist from a pre-curated list to set the morning mood. The same program runs at 8:30 PM to help us wind down after a long day.

- **Lighting control** <br/>
  Vision is connected to all the **Smart Lamps** in our House. It can power On/Off, toggle brightness, and set preprogrammed moods to these connected lamps. I can ask vision to dim the lights and play songs in the background to set the perfect dinner ambiance.
  This is real handy when especially when the smart lamps from different brands. There is no need to open 3 different apps to control individual bulbs.

- **Breathwork** <br/>
  Runs a Breathing exercise animation on the screen.

- **Headless Google Assistant** <br/>
  Why buy when you can assemble of your own! Google has published their [**Google Assistant SDK**](https://developers.google.com/assistant/sdk/guides/service/python) free for non-commercial uses. There are great [open source packages](https://github.com/shivasiddharth/Assistants-Pi) written which simplify this setup for a RPI system.

- **Doggo Cam** <br/>
  I have not been able to put the camera for good use. For now, I just use this to spy on our Doggo for any mischieves he is doing.

The following schematics may help give a better idea of all the interconnected systems and services.

<MediaGrid caption={'Vision Schematics'} photos={[{src: vision_schematics, width: 2202,height: 1194}]}/>

### Was it worth building?

100% yes! Techniques that I have mentioned here are not new and there are already great apps for everything that’s mentioned here.
But there’s no one size fits all solution. Vision helps me show the exact information that interests me without 100 other distractions.
The modular architecture helps me to connect new features to it when there’s a new need.

There is no comparison to the learning and satisfaction that one would get from creating something new, something **tangible**.
The whole process allows you to plan, focus, and enjoy the empowering feeling of creating something on your own.

I will be writing a follow up post with detailed steps if you want to build something like this.
The current state of code is not in its best shape to open source it, but that’s the aim!
If you have any suggestions to improve this setup please do share in the comments!
